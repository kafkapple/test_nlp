training:
  num_epochs: 20
  learning_rate: 1.0e-05
  train_batch_size: 50
  eval_batch_size: 32
  warmup_ratio: 0.1
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  fp16: true
  early_stopping:
    patience: 3
    threshold: 0.001

inference:
  batch_size: 32
  max_length: 100
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  remove_tokens:
    - <usr>
    - <s>
    - </s>
    - <pad> 